---
  title: "Non-Spatial Models, Mayer"
author: "Claire Kelling"
date: "June 11, 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
```

The purpose of this code is to fit the CAR model to voting data, aggregated by ward. We only have Census data by district and/or block group so this presents a spatial mismatch file. 

First, we will install all necessary packages.
```{r}
# Packages:
library(sp)
library(spdep)
library(classInt)
library(fields)
library(ggplot2)
library(dplyr)
library(ade4) 
library(igraph) 
library(CARBayesdata)
library(CARBayes)
library(gridExtra)
library(xtable)
library(stringi)
require(rgdal)
library(ngspatial)
library(plyr)
library(readxl)
library(glmnet)

#use to the following data:
#Datato be used in R, ForR_contested.R
```

Now, we will load the data, including the following:
 b* shape files
* demographics
* voting data
```{r}
#ward shape files
#wi_ward
ward_shp <- readOGR(dsn = "C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data", layer = "wiward")

#voting and demographic data
#quick fit with demographics
#demog_vote <- read.csv("C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/QuickFitWithDemographics.csv")

#final data used in model
ForR <- read_excel("C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/Data to be Used in R/ForR.xlsx")

#older drafts of the data
#ForR <- read_excel("C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/Reconciliation/ForR.xlsx")
#ForR_con <- read.csv("C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/Data to be Used in R/ForR_contested.csv")

#leaves out Dunn county
#response: WSAREP
#also use PREDEM

```

Now we need to join the spatial polygons and the demographic/voting data.
```{r}
#re-formatting to add the data to the shape file
ward_shp@data <- ward_shp@data[,-c(14:ncol(ward_shp@data))]

#check classes
class(ward_shp@data$OBJECTID_1)

#change column name for ID variables for which we will join
#colnames(demog_vote)[2] <- "GEOID"
colnames(ward_shp@data)[1] <- "GEOID"
colnames(ForR)[5] <- "GEOID"

#change to character variable
#demog_vote$GEOID <- as.character(demog_vote$GEOID)
ward_shp@data$GEOID <- as.character(ward_shp@data$GEOID)
ForR$GEOID <- as.character(ForR$GEOID)

#creating new variable
#demog_vote$IncumD_Pop <- demog_vote$Dincumbent*demog_vote$PERSONS18
#demog_vote$IncumR_Pop <- demog_vote$Rincumbent*demog_vote$PERSONS18

#join on GEOID
ward_shp@data <- left_join(ward_shp@data, ForR, by = (GEOID = "GEOID"))

#BBPRESDEM12 + BBPRESREP12+PERSONS18 +BLACK18 + WHITE18 + HISPANIC18+ IncumD_Pop + IncumR_Pop

# class(ward_shp@data$BBWSADEM12) 
# class(ward_shp@data$BBWSADEM12) 
# class(ward_shp@data$BBPRESDEM12) 
# class(ward_shp@data$BBPRESREP12)


# ward_shp@data$BBWSADEM12 <- round(as.numeric(ward_shp@data$BBWSADEM12))
# ward_shp@data$BBWSADEM12 <- round(as.numeric(ward_shp@data$BBWSADEM12))
# ward_shp@data$BBPRESDEM12 <- round(as.numeric(ward_shp@data$BBPRESDEM12))
# ward_shp@data$BBPRESREP12 <- round(as.numeric(ward_shp@data$BBPRESREP12))
# ward_shp@data$CWSADEM12 <- round(ward_shp@data$CWSADEM12)
# ward_shp@data$CWSAREP12 <- round(ward_shp@data$CWSAREP12)

#ward_shp@data$CWSADEM12 <- round(ward_shp@data$CWSADEM12)
#ward_shp@data$CWSAREP12 <- round(ward_shp@data$CWSAREP12)

ward_shp@data$c_wsa_dem12 <- round(ward_shp@data$c_wsa_dem12)
ward_shp@data$c_wsa_rep12 <- round(ward_shp@data$c_wsa_rep12)

#we have successfully joined the two datasets
```


Our first step in terms of modeling will be to run our model in a linear model and to test for spatial dependence. 
```{r}

#need to delete Object ID 6481 (outlier)
# range(ward_shp@data$c_wsa_dem12)
# out <- which(ward_shp@data$GEOID == 6481)
# ward_shp <- ward_shp[-out,]
# range(ward_shp@data$c_wsa_dem12)
# range(ward_shp@data$c_wsa_rep12)
# 
# ForR <- ForR[-which(ForR$GEOID == 6481),]
# range(ForR$c_wsa_dem12)

#we need to decide variables to use in our analysis
#colnames(demog_vote)

#create a variable for uncontested races
#unc <- unique(which(ward_shp@data$Contested == "U"))
# 0 if the race is uncontested, 1 if it is contested
unc <- unique(which(ward_shp@data$contested_1 == "0"))
con_shp <- ward_shp[-unc,]

#non-spatial modeling
#d.form <- CWSADEM12 ~ CPREDEM12 + CPREREP12+PERSONS18 +BLACK18  + HISPANIC18+ IncumD_Pop + IncumR_Pop 
#r.form <- CWSAREP12 ~ CPREDEM12 + CPREREP12+PERSONS18 +BLACK18  + HISPANIC18+ IncumD_Pop + IncumR_Pop 

d.form <- WSADEM12 ~ PREDEM12 + PREREP12+total_vep +black_vep + hisp_vep + dem_incum + rep_incum 
r.form <- WSAREP12 ~ PREDEM12 + PREREP12+total_vep +black_vep + hisp_vep + dem_incum + rep_incum 


#create linear models
c.d.model <- lm(formula=d.form, data=con_shp@data)
c.d.resid.model <- con_shp@data$WSADEM12 - c.d.model$fitted.values
c.r.model <- lm(formula=r.form, data=con_shp@data)
c.r.resid.model <- con_shp@data$WSAREP12 - c.r.model$fitted.values


#glm models
c.d.glm_model <- glm(formula=d.form, family = "poisson", data=con_shp@data)
c.d.resid.glm <- con_shp@data$WSADEM12 - c.d.glm_model$fitted.values
c.r.glm_model <- glm(formula=r.form, family = "poisson", data=con_shp@data)
c.r.resid.glm <- con_shp@data$WSAREP12 - c.r.glm_model$fitted.values


#test for spatial dependence
#null hypothesis of no spatial autocorrelation (alternative of positive spatial autocorrelation)
#also computes Moran's I statistic 
#if p-value < 0.05, we conclude there is positve spatial autocorrelation
W.nb.con <- poly2nb(con_shp, row.names = rownames(con_shp@data))

##############
### Creating adjacency matrix from nb
##############
W_mat_con <- nb2mat(W.nb.con, style="B", zero.policy=TRUE)


#############
### Moran's I Test
#############

W.list.con <- nb2listw(W.nb.con, style="B", zero.policy = TRUE)

moran.mc(x=c.d.resid.glm, listw=W.list.con, nsim=1000, zero.policy = TRUE)
moran.mc(x=c.r.resid.glm, listw=W.list.con, nsim=1000, zero.policy = TRUE)

#if p-value < 0.05, we conclude there is positve spatial autocorrelation

```


Check for overdispersion and implement a quasi-poisson model
```{r}
#check for overdispersion
glm.fit <- glm(formula=d.form, family = "poisson", data=con_shp@data, control = list(maxit = 1000))
summary(glm.fit)

# Possible Overdispersion;
# Check of Overdispersion
#check of dispersion parameter: 659073.1
sum(residuals(glm.fit, type="pearson")^2)/glm.fit$df.residual

glm.fit.quasi.d <- glm(formula=d.form, family = "quasipoisson", data=con_shp@data, control = list(maxit = 1000))
c.d.resid.qpois <- con_shp@data$WSADEM12 - glm.fit.quasi.d$fitted.values

glm.fit.quasi.r <- glm(formula=r.form, family = "quasipoisson", data=con_shp@data, control = list(maxit = 1000))
c.r.resid.qpois <- con_shp@data$WSAREP12 - glm.fit.quasi.r$fitted.values

### Model Diagnostics
fitted.mean <- predict.glm(glm.fit, type='link')
fitted.resp <- predict.glm(glm.fit, type='response')
fitted.var <- (con_shp@data$WSADEM12 - fitted.mean)^2

### Model Comparison: MSE
# fitted.mean <- (predict.glm(glm.fit.quasi, type='link'))
# fitted.resp <- (predict.glm(glm.fit.quasi, type='response'))
# fitted.var <- (full_data$num_downloads - fitted.mean)^2

mse <- sum(fitted.var)/nrow(con_shp@data)

fit.data <- data.frame(fitted.resp, fitted.var, fitted.mean)


ggplot(fit.data, aes(x=log(fit.data[,1])) )+
  geom_point(aes(y=log(fit.data[,2]), colour ="black"), size=3)+
  geom_abline(slope = 1, intercept = 0, color="red") +
  theme( legend.position= "none", axis.text=element_text(size=20), axis.title=element_text(size=20),
         text=element_text(size=18) ) +
  xlab(expression( 'Standardized '(hat(mu)) ) ) +
  scale_y_continuous(expression( 'Standardized '(y-hat(mu))^2 ) ) +
  scale_colour_identity() +
  xlim(c(0,20))+
  ggtitle(expression('Fitted Mean vs Fitted Variance, Dem Votes') ) #first num is 750 when saving

```


#Model Evaluation
Now, I will compare the models using mean-squared prediction error.

First, I need to set up predicted for each model and actual for both Democratic and Republican races.
```{r}
#72 districts  (uncontested)
#con_shp@data$ASM <- as.numeric(con_shp@data$ASM)
actual_tab <- cbind(con_shp@data$assembly, con_shp@data$WSADEM12, con_shp@data$WSAREP12)
actual_tab <- as.data.frame(actual_tab)

colnames(actual_tab) <- c("District", "actual_d", "actual_r")
actual_tab2 <- actual_tab %>% group_by(District) %>% dplyr::summarise(dem_votes=sum(actual_d), rep_votes = sum(actual_r))

length(which(actual_tab2[,2] > actual_tab2[,3])) #16 times that the dem was greater
length(which(actual_tab2[,3] > actual_tab2[,2])) #56 times that the rep was greater

con_actual_tab <- cbind(ForR$assembly, ForR$WSADEM12, ForR$WSAREP12)
con_actual_tab <- as.data.frame(con_actual_tab)

colnames(con_actual_tab) <- c("District", "actual_d", "actual_r")
con_actual_tab2 <- con_actual_tab %>% group_by(District) %>% dplyr::summarise(dem_votes=sum(actual_d), rep_votes = sum(actual_r))


```

Now, I will compute the MSPE for each model.
```{r}
#### Democratic Prediction:
#linear model
d.lm.mspe <- sqrt(mean((c.d.resid.model)^2))
#glm
d.glm.mspe <- sqrt(mean((c.d.resid.glm)^2))
#quasi pois
d.qpois.mspe <- sqrt(mean((c.d.resid.qpois)^2)) #this is the same as this model mainly adjusts the significance

#### Republican Prediction:
#linear model
r.lm.mspe <- sqrt(mean((c.r.resid.model)^2))
#glm
r.glm.mspe <- sqrt(mean((c.r.resid.glm)^2))
#quasi pois
r.qpois.mspe <- sqrt(mean((c.r.resid.qpois)^2))

rmspe_tab <- rbind(c(d.lm.mspe, d.glm.mspe),
                  c(r.lm.mspe, r.glm.mspe))#, r.sglmm.mspe))
#mspe_tab_count <- mspe_tab
colnames(rmspe_tab) <- c("lin", "glm")#, "sglmm")
rownames(rmspe_tab) <- c("Democrat", "Republican")

```



Creation of counterfactual scenario where there is no incumbent:
```{r}
#First, I will create the model dataframe
#WSADEM12 ~ PREDEM12 + PREREP12+total_vep +black_vep + hisp_vep + dem_incum + rep_incum 

mod_dat <- ForR[,c("PREDEM12", "PREREP12", "total_vep", "black_vep", "hisp_vep", "dem_incum", "rep_incum")]
mod_dat$int <- rep(1, nrow(mod_dat))
mod_dat <- cbind(mod_dat[,8], mod_dat[,1:7])

mod_dat2 <- con_shp@data[,c("PREDEM12", "PREREP12", "total_vep", "black_vep", "hisp_vep", "dem_incum", "rep_incum")]
mod_dat2$int <- rep(1, nrow(mod_dat2))
mod_dat2 <- cbind(mod_dat2[,8], mod_dat2[,1:7])

#create function that returns predicted values under counterfactual situation
pred_val <- function(coeffs.Dem, coeffs.Rep, mod_dat, expon){
  #mod_dat <- mod_dat2
  #no incumbent:
  # coeffs.Dem[7] <- 0
  # coeffs.Dem[8] <- 0
  # coeffs.Rep[7] <- 0
  # coeffs.Rep[8] <- 0
  
  #test2 <- data.frame(lapply(test, function(x) as.numeric(as.character(x))))
  tableDem <- as.matrix(mod_dat)%*%coeffs.Dem
  tableDem <- as.numeric(tableDem)
  if(expon == T){
    tableDem <- exp(tableDem) #this is when we have a GLM framework
  }
  tableDem <- cbind(tableDem, ForR$assembly)
  tableDem <- as.data.frame(tableDem)
  colnames(tableDem) <- c("votes", "District")
  
  length(unique(tableDem$District))
  
  v_table_d <- tableDem %>% group_by(District) %>% dplyr::summarise(dem_votes=sum(votes))
  
  tableRep <- as.matrix(mod_dat)%*%coeffs.Rep
  tableRep <- as.numeric(tableRep)
  if(expon == T){
    tableRep <- exp(tableRep) #this is when we have a GLM framework 
  }
  tableRep <- cbind(tableRep, ForR$assembly)
  tableRep <- as.data.frame(tableRep)
  colnames(tableRep) <- c("votes", "District")
  
  v_table_r <- tableRep %>% group_by(District) %>% dplyr::summarise(rep_votes=sum(votes))
  
  v_table <- left_join(v_table_d, v_table_r)
  
  colnames(v_table) <- c("District", "Dem.Votes", "Rep.Votes")
  v_table2 <- v_table
  return(v_table)
}


######
#Linear Model:
######

coeffs.Dem <-summary(c.d.model)$coefficients[,1]
coeffs.Rep <-summary(c.r.model)$coefficients[,1]

coeffs.Dem <- as.numeric(coeffs.Dem)
coeffs.Rep <- as.numeric(coeffs.Rep)

v_table_lm <- pred_val(coeffs.Dem, coeffs.Rep, mod_dat, F)
View(cbind(v_table_lm, con_actual_tab2))
length(which(v_table_lm[,2] > v_table_lm[,3])) #predicts 40
length(which(con_actual_tab2[,2] > con_actual_tab2[,3])) #actual 39

######
#GLM:
######


coeffs.Dem <-summary(c.d.glm_model)$coefficients[,1]
coeffs.Rep <-summary(c.r.glm_model)$coefficients[,1]

coeffs.Dem <- as.numeric(coeffs.Dem)
coeffs.Rep <- as.numeric(coeffs.Rep)

v_table_glm <- pred_val(coeffs.Dem, coeffs.Rep, mod_dat, T)
View(cbind(v_table_glm, con_actual_tab2))

length(which(v_table_glm[,2] > v_table_glm[,3])) #still only predicts 34
length(which(con_actual_tab2[,2] > con_actual_tab2[,3])) #actual 39


#write.csv(v_table_lm, file = 'C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/mod_fit/lin_mod.csv')
#write.csv(v_table_glm, file = 'C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/mod_fit/glm.csv')
```

Now, we will consider county fixed effects in our counterfactual scenario.

```{r}
#First, I will create the model dataframe
mod_dat <- ForR[,c("PREDEM12", "PREREP12", "total_vep", "black_vep", "hisp_vep", "dem_incum", "rep_incum")]
d_mod_dat <- con_shp@data[,c("WSADEM12", "PREDEM12", "PREREP12", "total_vep", "black_vep", "hisp_vep", "dem_incum", "rep_incum")]
r_mod_dat <- con_shp@data[,c("WSAREP12", "PREDEM12", "PREREP12", "total_vep", "black_vep", "hisp_vep", "dem_incum", "rep_incum")]

#con_shp@data$CON <- as.numeric(as.character(con_shp@data$CON))
length(unique(con_shp@data$county))
#length(unique(con_shp@data$county)) #want 72 unique counties

mod_mat <- model.matrix( ~ county - 1, data=con_shp@data )
d_mod_dat <- cbind(d_mod_dat, mod_mat)
r_mod_dat <- cbind(r_mod_dat, mod_mat)
mod_mat2 <- model.matrix( ~ county - 1, data=ForR)
mod_dat$int <- rep(1, nrow(mod_dat))
mod_dat <- cbind(mod_dat[,8], mod_dat[,1:7], mod_mat2)
colnames(mod_dat)[1]<- c("int")

#non-spatial modeling
#d.form <- WSADEM12 ~ .
#r.form <- WSAREP12 ~ .

d.form <- WSADEM12 ~ PREDEM12 + PREREP12+total_vep +black_vep + hisp_vep + dem_incum + rep_incum +county
r.form <- WSAREP12 ~ PREDEM12 + PREREP12+total_vep +black_vep + hisp_vep + dem_incum + rep_incum +county

co.d.model <- lm(formula=d.form, data=con_shp@data)
c.d.resid.model <- con_shp@data$WSADEM12 - co.d.model$fitted.values
co.r.model <- lm(formula=r.form, data=con_shp@data)
c.r.resid.model <- con_shp@data$WSAREP12 - co.r.model$fitted.values

# co.d.model <- lm(formula=d.form, data=d_mod_dat)
# c.d.resid.model <- con_shp@data$WSADEM12 - co.d.model$fitted.values
# co.r.model <- lm(formula=r.form, data=r_mod_dat)
# c.r.resid.model <- con_shp@data$WSAREP12 - co.r.model$fitted.values

#glm model

co.d.glm_model <- glm(formula=d.form, family = "poisson", data=con_shp@data)
c.d.resid.glm <- con_shp@data$WSADEM12 - co.d.glm_model$fitted.values
co.r.glm_model <- glm(formula=r.form, family = "poisson", data=con_shp@data)
c.r.resid.glm <- con_shp@data$WSAREP12 - co.r.glm_model$fitted.values

######
#Linear Model:
######

#take out columns with column sum = 0
#co_dat <- mod_dat[,-as.numeric(which(colSums(d_mod_dat) == 0))]

co_dat <- mod_dat[,-9] #taking out county Adams (no coefficient)

coeffs.Dem <-summary(co.d.model)$coefficients[,1]
coeffs.Rep <-summary(co.r.model)$coefficients[,1]

coeffs.Dem <- as.numeric(coeffs.Dem)
coeffs.Rep <- as.numeric(coeffs.Rep)

co_v_table_lm <- pred_val(coeffs.Dem, coeffs.Rep, co_dat, F)
View(cbind(co_v_table_lm, con_actual_tab2))
length(which(co_v_table_lm[,2] > co_v_table_lm[,3])) #predicts 42

######
#GLM:
######

coeffs.Dem <-summary(co.d.glm_model)$coefficients[,1]
coeffs.Rep <-summary(co.r.glm_model)$coefficients[,1]

coeffs.Dem <- as.numeric(coeffs.Dem)
coeffs.Rep <- as.numeric(coeffs.Rep)

co_v_table_glm <- pred_val(coeffs.Dem, coeffs.Rep, co_dat, T)
View(cbind(co_v_table_glm, con_actual_tab2))
length(which(co_v_table_glm[,2] > co_v_table_glm[,3])) #predicts 41


#linear model
co.d.lm.mspe <- sqrt(mean((c.d.resid.model)^2))
co.r.lm.mspe <- sqrt(mean((c.r.resid.model)^2))
#glm
co.d.glm.mspe <- sqrt(mean((c.d.resid.glm)^2))
co.r.glm.mspe <- sqrt(mean((c.r.resid.glm)^2))

mspe_tab <- rbind(c(d.lm.mspe, d.glm.mspe, co.d.lm.mspe, co.d.glm.mspe),#, d.sglmm.mspe),
                  c(r.lm.mspe, r.glm.mspe, co.r.lm.mspe, co.r.glm.mspe))#, r.sglmm.mspe))
#mspe_tab_count <- mspe_tab
colnames(mspe_tab) <- c("lin", "glm", "county lm", "county glm")#, "sglmm")
rownames(mspe_tab) <- c("Democrat", "Republican")
View(mspe_tab)

xtable(mspe_tab)

#write.csv(co_v_table_lm, file = 'C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/mod_fit/co_lin_mod.csv')
#write.csv(co_v_table_glm, file = 'C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/mod_fit/co_glm.csv')


#save.image(file = "C:/Users/ckell/Desktop/Summer 2018/MGGG/Regression/data/wi.ForR.final_workspace.Rdata")

```

Now, I will print model output for our presentation.
```{r}
#Bayesian model comparison
#xtable(bayes_mod_eval)

#mspe
xtable(mspe_tab)


#write.csv(actual_tab2, file = 'C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/count_by_dist.csv')
```


I will calculate the efficience gap based on these models.
```{r}

#efficiency gap based on different models
source('C:/Users/ckell/Desktop/Summer 2018/MGGG/Regression/regression/src/Mayer/05_EfficiencyGap.R')

eg_lin <- efficiency.gap(v_table_lm)
eg_glm <- efficiency.gap(v_table_glm[-which(co_v_table_glm$District == 53),])
eg_co_lin <- efficiency.gap(co_v_table_lm)
eg_co_glm <- efficiency.gap(co_v_table_glm[-which(co_v_table_glm$District == 53),])

#mean-median score
#calculated by mean(dem_vote_share)-median(dem_vote_share)
mm_lin <- mean_med(v_table_lm)
mm_glm <- mean_med(v_table_glm[-which(co_v_table_glm$District == 53),])
mm_co_lin <- mean_med(co_v_table_lm)
mm_co_glm <- mean_med(co_v_table_glm[-which(co_v_table_glm$District == 53),])


eval_metrics <- cbind(c(eg_lin, eg_glm, eg_co_lin, eg_co_glm),
                      c(mm_lin, mm_glm, mm_co_lin, mm_co_glm))

colnames(eval_metrics) <- c("Eff Gap", "Mean Med")
rownames(eval_metrics) <- c("lin", "glm", "county lm", "county glm")

xtable(eval_metrics, digits = 4)
?xtable

#save.image(file = "C:/Users/ckell/Desktop/Summer 2018/MGGG/Regression/data/wi.ForR.final_workspace.Rdata")
```

See how many each of the models got correct:
```{r}
#actual
length(which(actual_tab2[,3] > actual_tab2[,2])) #56, of the contested elections (72 possible)
act_dasm <- actual_tab2$District[which(actual_tab2[,3] > actual_tab2[,2])]
act_dasm0 <- actual_tab2$District[which(actual_tab2[,3] < actual_tab2[,2])]
class_act <- rep(NA,99)
class_act[act_dasm] <- 1
class_act[act_dasm0] <- 0

#lm
lm <- cbind(con_shp@data$assembly, c.d.model$fitted.values,c.r.model$fitted.values)
lm <- as.data.frame(lm)
colnames(lm) <- c("District", "lm_d", "lm_r")
lm <- lm %>% group_by(District) %>% dplyr::summarise(dem_votes=sum(lm_d), rep_votes = sum(lm_r))
length(which(lm[,3] > lm[,2] )) # 54 dem
lm_dasm <- lm$District[which(lm[,3] > lm[,2])]
lm_dasm0 <- lm$District[which(lm[,3] < lm[,2])]
class_lm <- rep(NA,99)
class_lm[lm_dasm] <- 1
class_lm[lm_dasm0] <- 0

sum(class_act == class_lm, na.rm=T) #68/72 correct

#glm
glm <- cbind(con_shp@data$assembly, c.d.glm_model$fitted.values,c.r.glm_model$fitted.values)
glm <- as.data.frame(glm)
colnames(glm) <- c("District", "glm_d", "glm_r")
glm <- glm %>% group_by(District) %>% dplyr::summarise(dem_votes=sum(glm_d), rep_votes = sum(glm_r))
length(which(glm[,3] > glm[,2] )) # 59 dem
glm_dasm <- glm$District[which(glm[,3] > glm[,2])]
glm_dasm0 <- glm$District[which(glm[,3] < glm[,2])]
class_glm <- rep(NA,99)
class_glm[glm_dasm] <- 1
class_glm[glm_dasm0] <- 0
sum(class_act == class_glm, na.rm=T) #69/72 correct

#co_lm
co_lm <- cbind(con_shp@data$assembly, co.d.model$fitted.values,co.r.model$fitted.values)
co_lm <- as.data.frame(co_lm)
colnames(co_lm) <- c("District", "co_lm_d", "co_lm_r")
co_lm <- co_lm %>% group_by(District) %>% dplyr::summarise(dem_votes=sum(co_lm_d), rep_votes = sum(co_lm_r))
length(which(co_lm[,3] > co_lm[,2] )) # 56 dem
colm_dasm <- co_lm$District[which(co_lm[,3] > co_lm[,2])]
colm_dasm0 <- co_lm$District[which(co_lm[,3] < co_lm[,2])]
class_colm <- rep(NA,99)
class_colm[colm_dasm] <- 1
class_colm[colm_dasm0] <- 0
sum(class_act == class_colm, na.rm=T) #70/72 correct

#co_glm
co_glm <- cbind(con_shp@data$assembly, co.d.glm_model$fitted.values,co.r.glm_model$fitted.values)
co_glm <- as.data.frame(co_glm)
colnames(co_glm) <- c("District", "co_glm_d", "co_glm_r")
co_glm <- co_glm %>% group_by(District) %>% dplyr::summarise(dem_votes=sum(co_glm_d), rep_votes = sum(co_glm_r))
length(which(co_glm[,3] > co_glm[,2] )) # 57 dem
coglm_dasm <- co_glm$District[which(co_glm[,3] > co_glm[,2])]
coglm_dasm0 <- co_glm$District[which(co_glm[,3] < co_glm[,2])]
class_coglm <- rep(NA,99)
class_coglm[coglm_dasm] <- 1
class_coglm[coglm_dasm0] <- 0
sum(class_act == class_coglm, na.rm=T) #69/72 correct

```


Test efficiency gap and mean-median score under non-counterfactual scenario.
```{r}
non_cf <- function(fitd, fitr){
  tableDem <- cbind(fitd, con_shp@data$assembly)
  tableDem <- as.data.frame(tableDem)
  colnames(tableDem) <- c("votes", "District")
  
  length(unique(tableDem$District))
  
  v_table_d <- tableDem %>% group_by(District) %>% dplyr::summarise(dem_votes=sum(votes))
  

  tableRep <- cbind(fitr, con_shp@data$assembly)
  tableRep <- as.data.frame(tableRep)
  colnames(tableRep) <- c("votes", "District")
  
  v_table_r <- tableRep %>% group_by(District) %>% dplyr::summarise(rep_votes=sum(votes))
  
  v_table <- left_join(v_table_d, v_table_r)
  
  colnames(v_table) <- c("District", "Dem.Votes", "Rep.Votes")
  return(v_table)
}

nocf_lm <- non_cf(c.d.model$fitted.values, c.r.model$fitted.values)
nocf_glm <- non_cf(c.d.glm_model$fitted.values, c.r.glm_model$fitted.values)
nocf_colm <- non_cf(co.d.model$fitted.values, co.r.model$fitted.values)
nocf_coglm <- non_cf(co.d.glm_model$fitted.values, co.r.glm_model$fitted.values)


#efficiency gap
colnames(actual_tab2) <- c("District", "Dem.Votes", "Rep.Votes")
eg_actual <- efficiency.gap(actual_tab2)
eg_lin <- efficiency.gap(nocf_lm)
eg_glm <- efficiency.gap(nocf_glm)
eg_co_lin <- efficiency.gap(nocf_colm)
eg_co_glm <- efficiency.gap(nocf_coglm)

#mean-median score
#calculated by mean(dem_vote_share)-median(dem_vote_share)
mm_actual <- mean_med(actual_tab2)
mm_lin <- mean_med(nocf_lm)
mm_glm <- mean_med(nocf_glm)
mm_co_lin <- mean_med(nocf_colm)
mm_co_glm <- mean_med(nocf_coglm)


eval_metrics <- cbind(c(eg_actual, eg_lin, eg_glm, eg_co_lin, eg_co_glm),
                      c(mm_actual, mm_lin, mm_glm, mm_co_lin, mm_co_glm))

colnames(eval_metrics) <- c("Eff Gap", "Mean Med")
rownames(eval_metrics) <- c("Actual", "lin", "glm", "county lm", "county glm")

eval_metrics <- as.data.frame(eval_metrics)

sd(eval_metrics$`Eff Gap`)
mean(eval_metrics$`Eff Gap`)

sd(eval_metrics$`Mean Med`)
mean(eval_metrics$`Mean Med`)

xtable(eval_metrics, digits = 4)
```



Lastly, we would also like to incorporate LASSO as a means for variable selection.
```{r}
## alpha = 1 gives lasso regression
## alpha = 0 gives ridge regression
## lasso

#we need a model matrix X
X <- as.matrix(mod_dat)
y1 <- ForR$WSADEM12
y2 <- ForR$WSAREP12

lasso=glmnet(x=X,y=y1,family="poisson",alpha=1,nlambda=100)

## use 10-fold crossvalidation to find the best lambda
cv.lasso=cv.glmnet(x=X,y=y1,alpha=1,nfolds=10,family="poisson")

## get lambda and best lasso fit
lambda.lasso=cv.lasso$lambda.min
lambda.lasso

## some plots
par(mfrow=c(1,2))
plot(cv.lasso)
abline(v=log(lambda.lasso))
plot(lasso,xvar="lambda")
abline(v=log(lambda.lasso))

## beta estimates for best lambda
betas.lasso=coef(cv.lasso)
betas.lasso
```


Ridge Regression
```{r}
## fit ridge (trying 100 different lambda values)
rr=glmnet(x=X,y=y1,family = "poisson",alpha=0,nlambda=100)
plot(rr,xvar="lambda",main="Ridge Regression Betas for Different Values of the Tuning Parameter")

## use 10-fold crossvalidation to find the best lambda
cv.rr=cv.glmnet(x=X,y=y1,family = "poisson",alpha=0,nfolds=10,nlambda=200)

## getting cvmspe from best value of lambda
cvmspe.rr=min(cv.rr$cvm)

## get lambda and best rr fit
lambda.rr=cv.rr$lambda.min
lambda.rr

## some plots
par(mfrow=c(1,2))
plot(cv.rr)
abline(v=log(lambda.rr))
plot(rr,xvar="lambda",main="Ridge Regression Betas for Different Values of the Tuning Parameter")
abline(v=log(lambda.rr))

## beta estimates for best lambda
betas.rr=coef(cv.rr,s="lambda.min")

fit=lm(WSADEM12 ~ PREDEM12 + PREREP12+total_vep +black_vep + hisp_vep + dem_incum + rep_incum +county,data=con_shp@data)
summary(fit)
betas.lm=coef(fit)

#plot(betas.rr,betas.lm,xlim=c(-6,6),ylim=c(-6,6))
#abline(0,1)

yhat.rr=predict(cv.rr,s="lambda.min",newx=as.matrix(X))
mspe.rr=mean((y1-yhat.rr)^2)
mspe.rr
```

