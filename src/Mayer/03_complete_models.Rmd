---
  title: "Non-Spatial Models, Mayer"
author: "Claire Kelling"
date: "June 11, 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The purpose of this code is to fit the CAR model to voting data, aggregated by ward. We only have Census data by district and/or block group so this presents a spatial mismatch file. 

First, we will install all necessary packages.
```{r}
# Packages:
library(sp)
library(spdep)
library(classInt)
library(fields)
library(ggplot2)
library(dplyr)
library(ade4) 
library(igraph) 
library(CARBayesdata)
library(CARBayes)
library(gridExtra)
library(xtable)
library(stringi)
require(rgdal)
library(ngspatial)
library(plyr)
library(readxl)

```

Now, we will load the data, including the following:
  * shape files
* demographics
* voting data
```{r}
#ward shape files
#wi_ward
ward_shp <- readOGR(dsn = "C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data", layer = "wiward")

#voting and demographic data
#quick fit with demographics
#demog_vote <- read.csv("C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/QuickFitWithDemographics.csv")

ForR <- read_excel("C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/Data to be Used in R/ForR.xlsx")

```

Now we need to join the spatial polygons and the demographic/voting data.
```{r}
#re-formatting to add the data to the shape file
ward_shp@data <- ward_shp@data[,-c(14:ncol(ward_shp@data))]

#check classes
class(ward_shp@data$OBJECTID_1)

#change column name for ID variables for which we will join
#colnames(demog_vote)[2] <- "GEOID"
colnames(ward_shp@data)[1] <- "GEOID"
colnames(ForR)[5] <- "GEOID"

#change to character variable
#demog_vote$GEOID <- as.character(demog_vote$GEOID)
ward_shp@data$GEOID <- as.character(ward_shp@data$GEOID)
ForR$GEOID <- as.character(ForR$GEOID)

#creating new variable
#demog_vote$IncumD_Pop <- demog_vote$Dincumbent*demog_vote$PERSONS18
#demog_vote$IncumR_Pop <- demog_vote$Rincumbent*demog_vote$PERSONS18

#join on GEOID
ward_shp@data <- left_join(ward_shp@data, ForR, by = (GEOID = "GEOID"))

#BBPRESDEM12 + BBPRESREP12+PERSONS18 +BLACK18 + WHITE18 + HISPANIC18+ IncumD_Pop + IncumR_Pop

# class(ward_shp@data$BBWSADEM12) 
# class(ward_shp@data$BBWSADEM12) 
# class(ward_shp@data$BBPRESDEM12) 
# class(ward_shp@data$BBPRESREP12)


# ward_shp@data$BBWSADEM12 <- round(as.numeric(ward_shp@data$BBWSADEM12))
# ward_shp@data$BBWSADEM12 <- round(as.numeric(ward_shp@data$BBWSADEM12))
# ward_shp@data$BBPRESDEM12 <- round(as.numeric(ward_shp@data$BBPRESDEM12))
# ward_shp@data$BBPRESREP12 <- round(as.numeric(ward_shp@data$BBPRESREP12))
# ward_shp@data$CWSADEM12 <- round(ward_shp@data$CWSADEM12)
# ward_shp@data$CWSAREP12 <- round(ward_shp@data$CWSAREP12)

ward_shp@data$c_wsa_dem12 <- round(ward_shp@data$c_wsa_dem12)
ward_shp@data$c_wsa_rep12 <- round(ward_shp@data$c_wsa_rep12)

#we have successfully joined the two datasets
```


Our first step in terms of modeling will be to run our model in a linear model and to test for spatial dependence. 
```{r}

#need to delete Object ID 6481 (outlier)
range(ward_shp@data$c_wsa_dem12)
out <- which(ward_shp@data$GEOID == 6481)
ward_shp <- ward_shp[-out,]
range(ward_shp@data$c_wsa_dem12)
range(ward_shp@data$c_wsa_rep12)

#we need to decide variables to use in our analysis
#colnames(demog_vote)

#create a variable for uncontested races
#unc <- unique(which(ward_shp@data$Contested == "U"))
unc <- unique(which(ward_shp@data$contested_1 == "0"))
con_shp <- ward_shp[-unc,]

#non-spatial modeling
#d.form <- CWSADEM12 ~ CPREDEM12 + CPREREP12+PERSONS18 +BLACK18  + HISPANIC18+ IncumD_Pop + IncumR_Pop 
#r.form <- CWSAREP12 ~ CPREDEM12 + CPREREP12+PERSONS18 +BLACK18  + HISPANIC18+ IncumD_Pop + IncumR_Pop 

d.form <- c_wsa_dem12 ~ c_pre_dem12 + c_pre_rep12+total_vep +black_vep + hisp_vep + dem_incum + rep_incum 
r.form <- c_wsa_rep12 ~ c_pre_dem12 + c_pre_rep12+total_vep +black_vep + hisp_vep + dem_incum + rep_incum 


#create linear models
c.d.model <- lm(formula=d.form, data=con_shp@data)
c.d.resid.model <- con_shp@data$c_wsa_dem12 - c.d.model$fitted.values
c.r.model <- lm(formula=r.form, data=con_shp@data)
c.r.resid.model <- con_shp@data$c_wsa_rep12 - c.r.model$fitted.values


#glm models
c.d.glm_model <- glm(formula=d.form, family = "poisson", data=con_shp@data)
c.d.resid.glm <- con_shp@data$c_wsa_dem12 - c.d.glm_model$fitted.values
c.r.glm_model <- glm(formula=r.form, family = "poisson", data=con_shp@data)
c.r.resid.glm <- con_shp@data$c_wsa_rep12 - c.r.glm_model$fitted.values


#test for spatial dependence
#null hypothesis of no spatial autocorrelation (alternative of positive spatial autocorrelation)
#also computes Moran's I statistic 
#if p-value < 0.05, we conclude there is positve spatial autocorrelation
W.nb.con <- poly2nb(con_shp, row.names = rownames(con_shp@data))

##############
### Creating adjacency matrix from nb
##############
W_mat_con <- nb2mat(W.nb.con, style="B", zero.policy=TRUE)


#############
### Moran's I Test
#############

W.list.con <- nb2listw(W.nb.con, style="B", zero.policy = TRUE)

moran.mc(x=c.d.resid.glm, listw=W.list.con, nsim=1000, zero.policy = TRUE)
moran.mc(x=c.r.resid.glm, listw=W.list.con, nsim=1000, zero.policy = TRUE)

#if p-value < 0.05, we conclude there is positve spatial autocorrelation

```


Check for overdispersion and implement a quasi-poisson model
```{r}
#check for overdispersion
glm.fit <- glm(formula=d.form, family = "poisson", data=con_shp@data, control = list(maxit = 1000))
summary(glm.fit)

# Possible Overdispersion;
# Check of Overdispersion
#check of dispersion parameter: 659073.1
sum(residuals(glm.fit, type="pearson")^2)/glm.fit$df.residual

glm.fit.quasi.d <- glm(formula=d.form, family = "quasipoisson", data=con_shp@data, control = list(maxit = 1000))
c.d.resid.qpois <- con_shp@data$c_wsa_dem12 - glm.fit.quasi.d$fitted.values

glm.fit.quasi.r <- glm(formula=r.form, family = "quasipoisson", data=con_shp@data, control = list(maxit = 1000))
c.r.resid.qpois <- con_shp@data$c_wsa_rep12 - glm.fit.quasi.r$fitted.values

### Model Diagnostics
fitted.mean <- predict.glm(glm.fit, type='link')
fitted.resp <- predict.glm(glm.fit, type='response')
fitted.var <- (con_shp@data$c_wsa_dem12 - fitted.mean)^2

### Model Comparison: MSE
# fitted.mean <- (predict.glm(glm.fit.quasi, type='link'))
# fitted.resp <- (predict.glm(glm.fit.quasi, type='response'))
# fitted.var <- (full_data$num_downloads - fitted.mean)^2

mse <- sum(fitted.var)/nrow(con_shp@data)

fit.data <- data.frame(fitted.resp, fitted.var, fitted.mean)


ggplot(fit.data, aes(x=log(fit.data[,1])) )+
  geom_point(aes(y=log(fit.data[,2]), colour ="black"), size=3)+
  geom_abline(slope = 1, intercept = 0, color="red") +
  theme( legend.position= "none", axis.text=element_text(size=20), axis.title=element_text(size=20),
         text=element_text(size=18) ) +
  xlab(expression( 'Standardized '(hat(mu)) ) ) +
  scale_y_continuous(expression( 'Standardized '(y-hat(mu))^2 ) ) +
  scale_colour_identity() +
  xlim(c(0,20))+
  ggtitle(expression('Fitted Mean vs Fitted Variance, Dem Votes') ) #first num is 750 when saving

```


#Model Evaluation
Now, I will compare the models using mean-squared prediction error.

First, I need to set up predicted for each model and actual for both Democratic and Republican races.
```{r}
#72 districts  (uncontested)
#con_shp@data$ASM <- as.numeric(con_shp@data$ASM)
actual_tab <- cbind(con_shp@data$assembly, con_shp@data$c_wsa_dem12, con_shp@data$c_wsa_rep12)
actual_tab <- as.data.frame(actual_tab)

colnames(actual_tab) <- c("District", "actual_d", "actual_r")
actual_tab2 <- actual_tab %>% group_by(District) %>% dplyr::summarise(dem_votes=sum(actual_d), rep_votes = sum(actual_r))

length(which(actual_tab2[,2] > actual_tab2[,3])) #17 times that the dem was greater
length(which(actual_tab2[,3] > actual_tab2[,2])) #17 times that the dem was greater
```

Now, I will compute the MSPE for each model.
```{r}
#### Democratic Prediction:
#linear model
d.lm.mspe <- sqrt(mean((c.d.resid.model)^2))
#glm
d.glm.mspe <- sqrt(mean((c.d.resid.glm)^2))
#quasi pois
d.qpois.mspe <- sqrt(mean((c.d.resid.qpois)^2)) #this is the same as this model mainly adjusts the significance

#### Republican Prediction:
#linear model
r.lm.mspe <- sqrt(mean((c.r.resid.model)^2))
#glm
r.glm.mspe <- sqrt(mean((c.r.resid.glm)^2))
#quasi pois
r.qpois.mspe <- sqrt(mean((c.r.resid.qpois)^2))

rmspe_tab <- rbind(c(d.lm.mspe, d.glm.mspe),
                  c(r.lm.mspe, r.glm.mspe))#, r.sglmm.mspe))
#mspe_tab_count <- mspe_tab
colnames(rmspe_tab) <- c("lin", "glm")#, "sglmm")
rownames(rmspe_tab) <- c("Democrat", "Republican")

```



Creation of counterfactual scenario where there is no incumbent:
```{r}
#First, I will create the model dataframe
#c_wsa_rep12 ~ c_pre_dem12 + c_pre_rep12+total_vep +black_vep + hisp_vep + dem_incum + rep_incum 

mod_dat <- ForR[,c("c_pre_dem12", "c_pre_rep12", "total_vep", "black_vep", "hisp_vep", "dem_incum", "rep_incum")]
mod_dat$int <- rep(1, nrow(mod_dat))
mod_dat <- cbind(mod_dat[,8], mod_dat[,1:7])

mod_dat2 <- con_shp@data[,c("c_pre_dem12", "c_pre_rep12", "total_vep", "black_vep", "hisp_vep", "dem_incum", "rep_incum")]
mod_dat2$int <- rep(1, nrow(mod_dat2))
mod_dat2 <- cbind(mod_dat2[,8], mod_dat2[,1:7])

#create function that returns predicted values under counterfactual situation
pred_val <- function(coeffs.Dem, coeffs.Rep, mod_dat, expon){
  #mod_dat <- mod_dat2
  coeffs.Dem[8] <- 0
  coeffs.Dem[9] <- 0
  coeffs.Rep[8] <- 0
  coeffs.Rep[9] <- 0
  
  #test2 <- data.frame(lapply(test, function(x) as.numeric(as.character(x))))
  tableDem <- as.matrix(mod_dat)%*%coeffs.Dem
  tableDem <- as.numeric(tableDem)
  if(expon == T){
    tableDem <- exp(tableDem) #this is when we have a GLM framework
  }
  tableDem <- cbind(tableDem, ForR$ASM)
  tableDem <- as.data.frame(tableDem)
  colnames(tableDem) <- c("votes", "District")
  
  length(unique(tableDem$District))
  
  v_table_d <- tableDem %>% group_by(District) %>% dplyr::summarise(dem_votes=sum(votes))
  
  tableRep <- as.matrix(mod_dat)%*%coeffs.Rep
  tableRep <- as.numeric(tableRep)
  if(expon = T){
    tableRep <- exp(tableRep) #this is when we have a GLM framework 
  }
  tableRep <- cbind(tableRep, ForR$ASM)
  tableRep <- as.data.frame(tableRep)
  colnames(tableRep) <- c("votes", "District")
  
  v_table_r <- tableRep %>% group_by(District) %>% dplyr::summarise(rep_votes=sum(votes))
  
  v_table <- left_join(v_table_d, v_table_r)
  
  colnames(v_table) <- c("District", "Dem. Votes", "Rep. Votes")
  v_table2 <- v_table
  return(v_table)
}


######
#Linear Model:
######

coeffs.Dem <-summary(c.d.model)$coefficients[,1]
coeffs.Rep <-summary(c.r.model)$coefficients[,1]

coeffs.Dem <- as.numeric(coeffs.Dem)
coeffs.Rep <- as.numeric(coeffs.Rep)

v_table_lm <- pred_val(coeffs.Dem, coeffs.Rep, mod_dat, F)
View(cbind(v_table_lm, actual_tab2))

######
#GLM:
######


coeffs.Dem <-summary(c.d.glm_model)$coefficients[,1]
coeffs.Rep <-summary(c.r.glm_model)$coefficients[,1]

coeffs.Dem <- as.numeric(coeffs.Dem)
coeffs.Rep <- as.numeric(coeffs.Rep)

v_table_glm <- pred_val(coeffs.Dem, coeffs.Rep, mod_dat, T)
View(cbind(v_table_glm, actual_tab2))

length(which(v_table_glm[,2] > v_table_glm[,3])) #still only predicts 3


#write.csv(v_table_lm, file = 'C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/mod_fit/lin_mod.csv')
#write.csv(v_table_glm, file = 'C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/mod_fit/glm.csv')
```

Now, we will consider county fixed effects in our counterfactual scenario.

```{r}
#First, I will create the model dataframe
mod_dat <- ForR[,c("c_pre_dem12", "c_pre_rep12", "total_vep", "black_vep", "hisp_vep", "dem_incum", "rep_incum")]
d_mod_dat <- con_shp@data[,c("c_wsa_dem12", "c_pre_dem12", "c_pre_rep12", "total_vep", "black_vep", "hisp_vep", "dem_incum", "rep_incum")]
r_mod_dat <- con_shp@data[,c("c_wsa_rep12", "c_pre_dem12", "c_pre_rep12", "total_vep", "black_vep", "hisp_vep", "dem_incum", "rep_incum")]

con_shp@data$CON <- as.numeric(as.character(con_shp@data$CON))
#length(unique(con_shp@data$CNTY_FIPS))
length(unique(con_shp@data$county)) #want 72 unique counties

mod_mat <- model.matrix( ~ county - 1, data=con_shp@data )
d_mod_dat <- cbind(d_mod_dat, mod_mat)
r_mod_dat <- cbind(r_mod_dat, mod_mat)
mod_mat2 <- model.matrix( ~ county - 1, data=ForR)
mod_dat$int <- rep(1, nrow(mod_dat))
mod_dat <- cbind(mod_dat[,9], mod_dat[,1:8], mod_mat2)
colnames(mod_dat)[1]<- c("int")

#non-spatial modeling
d.form <- CWSADEM12 ~ .
r.form <- CWSAREP12 ~ .

c.d.model <- lm(formula=d.form, data=d_mod_dat)
c.d.resid.model <- con_shp@data$CWSADEM12 - c.d.model$fitted.values
c.r.model <- lm(formula=r.form, data=r_mod_dat)
c.r.resid.model <- con_shp@data$CWSAREP12 - c.r.model$fitted.values

#glm model

c.d.glm_model <- glm(formula=d.form, family = "poisson", data=d_mod_dat)
c.d.resid.glm <- con_shp@data$CWSADEM12 - c.d.glm_model$fitted.values
c.r.glm_model <- glm(formula=r.form, family = "poisson", data=r_mod_dat)
c.r.resid.glm <- con_shp@data$CWSAREP12 - c.r.glm_model$fitted.values

######
#Linear Model:
######

#take out columns with column sum = 0
#co_dat <- mod_dat[,-as.numeric(which(colSums(d_mod_dat) == 0))]

co_dat <- mod_dat[,-81] #also taking out CountyYukon-Koyukuk Census Area`

coeffs.Dem <-summary(c.d.model)$coefficients[,1]
coeffs.Rep <-summary(c.r.model)$coefficients[,1]

coeffs.Dem <- as.numeric(coeffs.Dem)
coeffs.Rep <- as.numeric(coeffs.Rep)

co_v_table_lm <- pred_val(coeffs.Dem, coeffs.Rep, co_dat, F)
length(which(co_v_table_lm[,2] > co_v_table_lm[,3])) #still only predicts 4

######
#GLM:
######

coeffs.Dem <-summary(c.d.glm_model)$coefficients[,1]
coeffs.Rep <-summary(c.r.glm_model)$coefficients[,1]

coeffs.Dem <- as.numeric(coeffs.Dem)
coeffs.Rep <- as.numeric(coeffs.Rep)

co_v_table_glm <- pred_val(coeffs.Dem, coeffs.Rep, co_dat, T)

length(which(co_v_table_glm[,2] > co_v_table_glm[,3])) #still only predicts 4


#linear model
co.d.lm.mspe <- mean((c.d.resid.model)^2)
co.r.lm.mspe <- mean((c.r.resid.model)^2)
#glm
co.d.glm.mspe <- mean((c.d.resid.glm)^2)
co.r.glm.mspe <- mean((c.r.resid.glm)^2)

mspe_tab <- rbind(c(d.lm.mspe, d.glm.mspe, co.d.lm.mspe, co.d.glm.mspe),#, d.sglmm.mspe),
                  c(r.lm.mspe, r.glm.mspe, co.r.lm.mspe, co.r.glm.mspe))#, r.sglmm.mspe))
#mspe_tab_count <- mspe_tab
colnames(mspe_tab) <- c("lin", "glm", "county lm", "county glm")#, "sglmm")
rownames(mspe_tab) <- c("Democrat", "Republican")
View(mspe_tab)

#write.csv(co_v_table_lm, file = 'C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/mod_fit/co_lin_mod.csv')
#write.csv(co_v_table_glm, file = 'C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/mod_fit/co_glm.csv')


#save.image(file = "C:/Users/ckell/Desktop/Summer 2018/MGGG/Regression/data/wi.ForR.final_workspace.Rdata")

```

Now, I will print model output for our presentation.
```{r}
#Bayesian model comparison
xtable(bayes_mod_eval)

#mspe
xtable(mspe_tab)


write.csv(actual_tab2, file = 'C:/Users/ckell/Dropbox/Gerrycamp Regressions Project/Mayer Project/data/count_by_dist.csv')
```


I will calculate the efficience gap based on these models.
```{r}

```

